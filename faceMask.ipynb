{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-oLn40C3xRDR"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os\n",
    "import numpy as np \n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, datasets, transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import numpy as np \n",
    "import argparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "fontScale = 1\n",
    "color = (255, 0, 0) \n",
    "thickness = 2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "maskModel = models.resnet34()\n",
    "maskModel.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "maskModel.load_state_dict(torch.load('./model98.pth'))\n",
    "maskModel.to(device)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "\n",
    "transform_video = transforms.Compose([transforms.Resize(256),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),(0.247, 0.243, 0.261))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_yolo():\n",
    "    net = cv2.dnn.readNet(\"yolov3-tiny.weights\", \"yolov3-tiny.cfg\")\n",
    "    classes = []\n",
    "    with open(\"coco.names\", \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    layers_names = net.getLayerNames()\n",
    "    output_layers = [layers_names[i[0]-1] for i in net.getUnconnectedOutLayers()]\n",
    "    colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "    return net, classes, colors, output_layers\n",
    "\n",
    "\n",
    "def detect_objects(img, net, outputLayers):\n",
    "    blob = cv2.dnn.blobFromImage(img, scalefactor=0.00392, size=(320, 320), mean=(0, 0, 0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward(outputLayers)\n",
    "    return blob, outputs\n",
    "\n",
    "\n",
    "def get_box_dimensions(outputs, height, width):\n",
    "    boxes = []\n",
    "    confs = []\n",
    "    class_ids = []\n",
    "    for output in outputs:\n",
    "        for detect in output:\n",
    "            scores = detect[5:]\n",
    "            print(scores)\n",
    "            class_id = np.argmax(scores)\n",
    "            conf = scores[class_id]\n",
    "            if conf > 0.3:\n",
    "                center_x = int(detect[0] * width)\n",
    "                center_y = int(detect[1] * height)\n",
    "                w = int(detect[2] * width)\n",
    "                h = int(detect[3] * height)\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confs.append(float(conf))\n",
    "                class_ids.append(class_id)\n",
    "    return boxes, confs, class_ids\n",
    "\n",
    "\n",
    "def draw_labels(boxes, confs, colors, class_ids, classes, img): \n",
    "    people = []\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confs, 0.5, 0.4)\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            color = colors[i]\n",
    "            if(label == \"person\"):\n",
    "                people.append([x,y,w,h])\n",
    "                cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "                cv2.putText(img, label, (x, y - 5), font, 1, color, 1)\n",
    "    return people\n",
    "\n",
    "\n",
    "yolo_model, yolo_classes, yolo_colors, yolo_output_layers = load_yolo()\n",
    "\n",
    "def humanDetection(frame):\n",
    "    height, width, channels = frame.shape\n",
    "    blob, outputs = detect_objects(frame, yolo_model, yolo_output_layers)\n",
    "    boxes, confs, class_ids = get_box_dimensions(outputs, height, width)\n",
    "    people = draw_labels(boxes, confs, yolo_colors, class_ids, yolo_classes, frame)\n",
    "    \n",
    "    if people ==[] : \n",
    "        return False, people\n",
    "    else:\n",
    "        return True, people\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "COCO_INSTANCE_CATEGORY_NAMES = (\n",
    "    \"__background__\",\n",
    "    \"person\",\n",
    "    \"bicycle\",\n",
    "    \"car\",\n",
    "    \"motorcycle\",\n",
    "    \"airplane\",\n",
    "    \"bus\",\n",
    "    \"train\",\n",
    "    \"truck\",\n",
    "    \"boat\",\n",
    "    \"traffic light\",\n",
    "    \"fire hydrant\",\n",
    "    \"N/A\",\n",
    "    \"stop sign\",\n",
    "    \"parking meter\",\n",
    "    \"bench\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"dog\",\n",
    "    \"horse\",\n",
    "    \"sheep\",\n",
    "    \"cow\",\n",
    "    \"elephant\",\n",
    "    \"bear\",\n",
    "    \"zebra\",\n",
    "    \"giraffe\",\n",
    "    \"N/A\",\n",
    "    \"backpack\",\n",
    "    \"umbrella\",\n",
    "    \"N/A\",\n",
    "    \"N/A\",\n",
    "    \"handbag\",\n",
    "    \"tie\",\n",
    "    \"suitcase\",\n",
    "    \"frisbee\",\n",
    "    \"skis\",\n",
    "    \"snowboard\",\n",
    "    \"sports ball\",\n",
    "    \"kite\",\n",
    "    \"baseball bat\",\n",
    "    \"baseball glove\",\n",
    "    \"skateboard\",\n",
    "    \"surfboard\",\n",
    "    \"tennis racket\",\n",
    "    \"bottle\",\n",
    "    \"N/A\",\n",
    "    \"wine glass\",\n",
    "    \"cup\",\n",
    "    \"fork\",\n",
    "    \"knife\",\n",
    "    \"spoon\",\n",
    "    \"bowl\",\n",
    "    \"banana\",\n",
    "    \"apple\",\n",
    "    \"sandwich\",\n",
    "    \"orange\",\n",
    "    \"broccoli\",\n",
    "    \"carrot\",\n",
    "    \"hot dog\",\n",
    "    \"pizza\",\n",
    "    \"donut\",\n",
    "    \"cake\",\n",
    "    \"chair\",\n",
    "    \"couch\",\n",
    "    \"potted plant\",\n",
    "    \"bed\",\n",
    "    \"N/A\",\n",
    "    \"dining table\",\n",
    "    \"N/A\",\n",
    "    \"N/A\",\n",
    "    \"toilet\",\n",
    "    \"N/A\",\n",
    "    \"tv\",\n",
    "    \"laptop\",\n",
    "    \"mouse\",\n",
    "    \"remote\",\n",
    "    \"keyboard\",\n",
    "    \"cell phone\",\n",
    "    \"microwave\",\n",
    "    \"oven\",\n",
    "    \"toaster\",\n",
    "    \"sink\",\n",
    "    \"refrigerator\",\n",
    "    \"N/A\",\n",
    "    \"book\",\n",
    "    \"clock\",\n",
    "    \"vase\",\n",
    "    \"scissors\",\n",
    "    \"teddy bear\",\n",
    "    \"hair drier\",\n",
    "    \"toothbrush\",\n",
    ")\n",
    "\n",
    "\n",
    "# define the torchvision image transforms\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "MIN_SIZE = 800\n",
    "\n",
    "\n",
    "# download or load the model from disk\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, min_size=MIN_SIZE)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def predict(image, detection_threshold):\n",
    "    # transform the image to tensor\n",
    "    image = transform(image).to(device)\n",
    "    image = image.unsqueeze(0)  # add a batch dimension\n",
    "    outputs = model(image)  # get the predictions on the image\n",
    "    # get all the predicited class names\n",
    "    labels = outputs[0][\"labels\"].cpu().numpy()\n",
    "    # get score for all persons\n",
    "    pred_scores = outputs[0][\"scores\"].detach().cpu().numpy()\n",
    "    # get all the predicted bounding boxes\n",
    "    pred_bboxes = outputs[0][\"boxes\"].detach().cpu().numpy()\n",
    "    # get all outputs of class person\n",
    "    pred_bboxes = pred_bboxes[labels == 1]\n",
    "    pred_scores = pred_scores[labels == 1]\n",
    "    # return boxes above the threshold score\n",
    "    return pred_bboxes[pred_scores >= detection_threshold].astype(np.int32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(box, image, color, message):\n",
    "    image = np.asarray(image)\n",
    "    cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]) +int(box[0])   , int(box[3]) + int(box[1])), color, 4)\n",
    "    cv2.putText(image, message, (int(box[0]), int(box[1] - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "    return image\n",
    "\n",
    "\n",
    "def run(input_image):\n",
    "    image = Image.fromarray(input_image.astype('uint8'), 'RGB')\n",
    "    model.eval().to(device)\n",
    "    boxes = predict(image, 0.85)\n",
    "#     print(boxes)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDr3InLgxUdF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "F8oA7PkNxUgY"
   },
   "outputs": [],
   "source": [
    "def crop(image , x, y, h, w):\n",
    "    return image[y:y+h, x:x+w]\n",
    "\n",
    "\n",
    "def face(image):\n",
    "    r = False\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # You must enter the values for the parameters denoted with an x\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=4\n",
    "        #flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        image = crop(image, x, y, h, w )\n",
    "        r = True \n",
    "    \n",
    "    return r, faces \n",
    "\n",
    "def humanDetector(image):\n",
    "    box = run(image)\n",
    "    if box == ():\n",
    "        return False , box\n",
    "    else:\n",
    "        return True , box\n",
    "\n",
    "def maskDectector(image):\n",
    "    image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
    "    image = train_transform(image).to(device)\n",
    "    image = image.unsqueeze(0)\n",
    "    output = maskModel(image)\n",
    "    _, pred = torch.max(output.data, 1)\n",
    "    [pred] = pred.detach().cpu().numpy()\n",
    "    return not pred \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "id": "mRipx9XTxUky",
    "outputId": "eb232823-a28a-47fa-c0bb-82b5fac0c5ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woolllff/.conda/envs/vr/lib/python3.6/site-packages/ipykernel_launcher.py:26: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "       \n",
    "\n",
    "\n",
    "while(True):\n",
    "    ret , frame = cap.read()\n",
    "    \n",
    "    isHuman = True\n",
    "    isFace  = False\n",
    "    isMask  = False\n",
    "\n",
    "    isHuman, humanBoxes= humanDetector(frame)\n",
    "    if isHuman:\n",
    "        for [x,y,w,h] in humanBoxes:\n",
    "            human = crop(frame,x,y,h,w)\n",
    "            isFace , faces = face(human)\n",
    "            if isFace :\n",
    "                for (xf,yf,wf,hf) in faces:\n",
    "                    faceHuman = crop(human,xf,yf,hf,wf)\n",
    "                    isMask = maskDectector(human)\n",
    "                    if isMask:\n",
    "                        frame = draw_boxes([x+xf,y+yf,wf,hf], frame,(0,255,0), \"mask on\")\n",
    "                        # cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0) , 2)\n",
    "                        # cv2.putText(frame, \"Mask on\", (x, y - 5), font, 1, (0,255,0) , 1)\n",
    "                    else:\n",
    "                        frame = draw_boxes([x+xf,y+yf,wf,hf], frame,(0,0,255), \"mask off\")\n",
    "                        # cv2.rectangle(frame, (x,y), (x+w, y+h), (0,0,255) , 2)\n",
    "                        # cv2.putText(frame, \"Mask off\", (x, y - 5), font, 1, (0,0,255) , 1)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"capture\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# isHuman = True\n",
    "# isFace  = False\n",
    "# isMask  = False\n",
    "\n",
    "# frame = cv2.imread(\"/home/woolllff/Desktop/vr/miniproj/data/mask/augmented_image_231.jpg\")\n",
    "\n",
    "# isHuman, humanBoxes= humanDetector(frame)\n",
    "# if isHuman:\n",
    "#     for [x,y,w,h] in humanBoxes:\n",
    "#         human = crop(frame,x,y,h,w)\n",
    "#         isFace , faces = face(human)\n",
    "#         if isFace :\n",
    "#             for (xf,yf,wf,hf) in faces:\n",
    "#                 faceHuman = crop(human,xf,yf,hf,wf)\n",
    "#                 isMask = maskDectector(faceHuman)\n",
    "#                 if isMask:\n",
    "#                     frame = draw_boxes([x+xf,y+yf,wf,hf], frame,(0,255,0), \"mask on\")\n",
    "                 \n",
    "#                 else:\n",
    "#                     frame = draw_boxes([x+xf,y+yf,wf,hf], frame,(0,0,255), \"mask off\")\n",
    "               \n",
    "\n",
    "\n",
    "# cv2.imshow(\"capture\", frame)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "faceMask.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
